import React, { useState, useRef, useEffect } from 'react';
import { useNavigate } from 'react-router-dom';
import * as speechsdk from 'microsoft-cognitiveservices-speech-sdk';

// ê°ì • ë¶„ì„ì„ ìœ„í•œ ì¸í„°í˜ì´ìŠ¤
interface EmotionAnalysis {
  confidence: number;
  emotion: 'ìì‹ ìˆìŒ' | 'ê¸´ì¥ë¨';
  details: {
    speed: number;
    volume: number;
    pitchVariance: number;
    pauseCount: number;
  };
}

// ë‹¨ì–´ë³„ ì ìˆ˜ë¥¼ ìœ„í•œ ì¸í„°í˜ì´ìŠ¤
interface WordScore {
  text: string;
  score: number;
}

// ì—´í™”ìƒ ì§€ë„ ì»´í¬ë„ŒíŠ¸
const HeatMapVisualization: React.FC<{ wordScores: WordScore[] }> = ({ wordScores }) => {
  const canvasRef = useRef<HTMLCanvasElement>(null);

  useEffect(() => {
    const canvas = canvasRef.current;
    if (!canvas) return;

    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // ìº”ë²„ìŠ¤ í¬ê¸° ì¡°ì •
    const containerWidth = canvas.parentElement?.clientWidth || 800;
    canvas.width = containerWidth;
    canvas.height = 60;

    // ë‹¨ì–´ë‹¹ ë„ˆë¹„ ê³„ì‚° (ìµœì†Œ 80px)
    const wordWidth = Math.max(80, containerWidth / wordScores.length - 5);

    // ìº”ë²„ìŠ¤ ì´ˆê¸°í™”
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    wordScores.forEach((word, index) => {
      const x = index * (wordWidth + 5);
      
      // ê·¸ë¼ë°ì´ì…˜ ë°°ê²½
      const gradient = ctx.createLinearGradient(x, 0, x + wordWidth, 0);
      const score = word.score / 100;
      gradient.addColorStop(0, `rgba(${255 * (1 - score)}, ${255 * score}, 100, 0.9)`);
      gradient.addColorStop(1, `rgba(${255 * (1 - score)}, ${255 * score}, 100, 0.7)`);
      
      // ë‹¨ì–´ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
      ctx.fillStyle = gradient;
      ctx.fillRect(x, 0, wordWidth, 50);
      
      // í…Œë‘ë¦¬ ì¶”ê°€
      ctx.strokeStyle = 'rgba(255, 255, 255, 0.3)';
      ctx.strokeRect(x, 0, wordWidth, 50);
      
      // ê¸€ì í‘œì‹œ
      ctx.fillStyle = 'white';
      ctx.font = 'bold 14px Arial';
      ctx.textAlign = 'center';
      ctx.fillText(word.text, x + wordWidth / 2, 25);
      
      // ì ìˆ˜ í‘œì‹œ
      ctx.font = '12px Arial';
      ctx.fillText(`${Math.round(word.score)}%`, x + wordWidth / 2, 45);
    });
  }, [wordScores]);

  return (
    <div className="w-full overflow-x-auto p-2 bg-gray-50 rounded-lg">
      <canvas 
        ref={canvasRef}
        className="w-full h-[60px] rounded-lg shadow-inner"
      />
    </div>
  );
};

// íŒŒë„ ì• ë‹ˆë©”ì´ì…˜ ì»´í¬ë„ŒíŠ¸
const WaveAnimation: React.FC<{ fluencyScore: number }> = ({ fluencyScore }) => {
  const waveIntensity = fluencyScore / 100;

  return (
    <div className="wave-container relative h-32 overflow-hidden bg-gradient-to-br from-blue-50 to-indigo-50 rounded-lg shadow-inner">
      <div 
        className="wave absolute bottom-0 left-0 w-full bg-gradient-to-r from-blue-400 to-indigo-400 transition-all duration-500"
        style={{
          height: `${30 + fluencyScore * 0.4}%`,
          animation: `wave ${2 - waveIntensity}s ease-in-out infinite`,
          opacity: 0.8,
          filter: 'blur(2px)',
        }}
      />
      <div 
        className="wave absolute bottom-0 left-0 w-full bg-gradient-to-r from-blue-300 to-indigo-300 transition-all duration-500"
        style={{
          height: `${20 + fluencyScore * 0.4}%`,
          animation: `wave ${2.5 - waveIntensity}s ease-in-out infinite`,
          animationDelay: '0.3s',
          opacity: 0.6,
          filter: 'blur(1px)',
        }}
      />
      <div className="absolute top-0 left-0 w-full h-full flex items-center justify-center">
        <span className="text-2xl font-bold text-white text-shadow">
          {Math.round(fluencyScore)}%
        </span>
      </div>
    </div>
  );
};

// ê°ì • ë¶„ì„ í•¨ìˆ˜
const analyzeConfidence = (speechData: any): EmotionAnalysis => {
  let confidenceScore = 100;
  const details = {
    speed: speechData.duration ? (speechData.text.split(' ').length / speechData.duration) * 60 : 0,
    volume: speechData.volume || 0,
    pitchVariance: speechData.pitch?.variance || 0,
    pauseCount: (speechData.pausePattern || []).filter((p: any) => p.duration > 0.5).length
  };
  
  // 1. ë§í•˜ëŠ” ì†ë„ ë¶„ì„
  if (details.speed > 180) {
    confidenceScore -= 10; // ë„ˆë¬´ ë¹¨ë¼ì„œ ê¸´ì¥í•œ ê²ƒ ê°™ìŒ
  }
  
  // 2. ìŒëŸ‰ ë¶„ì„
  if (details.volume < 0.3) {
    confidenceScore -= 15; // ëª©ì†Œë¦¬ê°€ ì‘ìŒ = ìì‹ ê° ë¶€ì¡±
  }
  
  // 3. ë§ì„¤ì„ íŒ¨í„´
  confidenceScore -= (details.pauseCount * 5);
  
  // 4. ìŒì„± ë–¨ë¦¼ (pitch variance)
  if (details.pitchVariance > 80) {
    confidenceScore -= 20; // ëª©ì†Œë¦¬ ë–¨ë¦¼ = ê¸´ì¥
  }
  
  const finalScore = Math.max(0, confidenceScore);
  
  return {
    confidence: finalScore,
    emotion: finalScore > 70 ? 'ìì‹ ìˆìŒ' : 'ê¸´ì¥ë¨',
    details
  };
};

interface DetailedPronunciationAssessmentWord {
  Word: string;
  AccuracyScore: number;
  ErrorType?: string;
}

interface DetailedPronunciationAssessment {
  Words?: DetailedPronunciationAssessmentWord[];
}

interface AzurePronunciationResult {
  accuracyScore: number;
  fluencyScore: number;
  completenessScore: number;
  pronunciationScore: number;
  detailedPronunciationAssessment?: DetailedPronunciationAssessment;
}

interface PronunciationAssessmentResult {
  accuracyScore: number;
  fluencyScore: number;
  completenessScore: number;
  pronScore: number;
  words?: Array<{
    word: string;
    accuracyScore: number;
    errorType?: string;
  }>;
}

const ShadowingPractice: React.FC = () => {
  const navigate = useNavigate();

  // ìƒíƒœ ê´€ë¦¬
  const [language, setLanguage] = useState<'ko-KR' | 'zh-CN'>('ko-KR');
  const [showText, setShowText] = useState(true);
  const [isPlaying, setIsPlaying] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [currentText, setCurrentText] = useState('');
  const [recordedText, setRecordedText] = useState('');
  const [assessmentResult, setAssessmentResult] = useState<PronunciationAssessmentResult | null>(null);
  const [emotionResult, setEmotionResult] = useState<EmotionAnalysis | null>(null);
  const [wordScores, setWordScores] = useState<WordScore[]>([]);

  // Azure Speech SDK ì„¤ì •
  const speechConfig = useRef<speechsdk.SpeechConfig | null>(null);
  const audioConfig = useRef<speechsdk.AudioConfig | null>(null);
  const recognizer = useRef<speechsdk.SpeechRecognizer | null>(null);
  const player = useRef<HTMLAudioElement | null>(null);

  // ìƒ˜í”Œ í…ìŠ¤íŠ¸ (ì‹¤ì œë¡œëŠ” DBë‚˜ APIì—ì„œ ê°€ì ¸ì˜¬ ê²ƒ)
  const sampleTexts = {
    'ko-KR': 'ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ ì°¸ ì¢‹ë„¤ìš”.',
    'zh-CN': 'ä½ å¥½ã€‚ä»Šå¤©å¤©æ°”çœŸä¸é”™ã€‚'
  };

  useEffect(() => {
    initializeAzureSpeech();
    return () => {
      if (recognizer.current) {
        try {
          // ë¹„ë™ê¸° ì •ë¦¬ ì‘ì—…ì„ ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬
          recognizer.current.stopContinuousRecognitionAsync();
          recognizer.current.close();
        } catch (error) {
          if (error instanceof Error) {
            console.log('Recognizer cleanup error:', error.message);
          }
        }
      }
    };
  }, [language]);

  const initializeAzureSpeech = async () => {
    try {
      const subscriptionKey = import.meta.env.VITE_AZURE_SPEECH_KEY;
      const region = import.meta.env.VITE_AZURE_SPEECH_REGION;
      const endpoint = import.meta.env.VITE_AZURE_SPEECH_ENDPOINT;

      // í™˜ê²½ë³€ìˆ˜ ê²€ì¦
      if (!subscriptionKey || !region) {
        console.error('Azure Speech Service í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤:', {
          VITE_AZURE_SPEECH_KEY: subscriptionKey ? 'ì„¤ì •ë¨' : 'ëˆ„ë½',
          VITE_AZURE_SPEECH_REGION: region ? 'ì„¤ì •ë¨' : 'ëˆ„ë½'
        });
        throw new Error('Azure Speech Service ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
      }

      console.log('Azure ì„¤ì • í™•ì¸:', {
        region,
        endpoint: endpoint || 'ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©',
        language
      });

      speechConfig.current = endpoint
        ? speechsdk.SpeechConfig.fromEndpoint(new URL(endpoint), subscriptionKey)
        : speechsdk.SpeechConfig.fromSubscription(subscriptionKey, region);

      speechConfig.current.speechRecognitionLanguage = language;

      console.log('Azure Speech Service ì´ˆê¸°í™” ì™„ë£Œ');
    } catch (error) {
      console.error('Azure Speech Service ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      alert('ìŒì„± ì„œë¹„ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    }
  };

  // ë§ˆì´í¬ ê¶Œí•œ í™•ì¸ í•¨ìˆ˜
  const checkMicrophonePermission = async (): Promise<boolean> => {
    try {
      // HTTPS ì²´í¬
      if (window.location.protocol !== 'https:' && window.location.hostname !== 'localhost') {
        throw new Error('ë§ˆì´í¬ ì ‘ê·¼ì€ HTTPS ë˜ëŠ” localhost í™˜ê²½ì—ì„œë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.');
      }

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      stream.getTracks().forEach(track => track.stop()); // ì²´í¬ í›„ ìŠ¤íŠ¸ë¦¼ í•´ì œ
      return true;
    } catch (error) {
      console.error('ë§ˆì´í¬ ê¶Œí•œ í™•ì¸ ì‹¤íŒ¨:', error);
      if (error instanceof Error) {
        alert(`ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤: ${error.message}`);
      }
      return false;
    }
  };

  const startRecording = async () => {
    if (!speechConfig.current) return;

    try {
      // ì´ì „ recognizerê°€ ìˆë‹¤ë©´ ì •ë¦¬
      if (recognizer.current) {
        try {
          await recognizer.current.stopContinuousRecognitionAsync();
          recognizer.current.close();
        } catch (error) {
          if (error instanceof Error) {
            console.log('Previous recognizer cleanup error:', error.message);
          }
        }
      }

      // ë§ˆì´í¬ ê¶Œí•œ í™•ì¸
      const hasMicPermission = await checkMicrophonePermission();
      if (!hasMicPermission) {
        return;
      }

      // ë§ˆì´í¬ ì„¤ì •
      audioConfig.current = speechsdk.AudioConfig.fromDefaultMicrophoneInput();
      
      // ë°œìŒ í‰ê°€ ì„¤ì •
      const pronunciationConfig = new speechsdk.PronunciationAssessmentConfig(
        sampleTexts[language],
        speechsdk.PronunciationAssessmentGradingSystem.HundredMark,
        speechsdk.PronunciationAssessmentGranularity.Word,
        true
      );

      // ì¸ì‹ê¸° ì„¤ì •
      recognizer.current = new speechsdk.SpeechRecognizer(
        speechConfig.current,
        audioConfig.current
      );

      // ë°œìŒ í‰ê°€ ì ìš©
      pronunciationConfig.applyTo(recognizer.current);
      console.log('ë°œìŒ í‰ê°€ ì„¤ì • ì ìš©ë¨');

      // ê²°ê³¼ ì²˜ë¦¬
      recognizer.current.recognized = (s: unknown, e: speechsdk.SpeechRecognitionEventArgs) => {
        const result = e.result;
        if (result.reason === speechsdk.ResultReason.NoMatch) {
          console.log('No speech could be recognized');
          return;
        }
        setRecordedText(result.text);

        try {
          // ì „ì²´ ì‘ë‹µ ë¡œê¹…
          const jsonResponse = JSON.parse(
            result.properties.getProperty(
              speechsdk.PropertyId.SpeechServiceResponse_JsonResult
            )
          );
          console.log('ì „ì²´ ì‘ë‹µ:', jsonResponse);

          // ë°œìŒ í‰ê°€ ê²°ê³¼ í™•ì¸
          const nBestResult = jsonResponse.NBest?.[0];
          if (!nBestResult?.PronunciationAssessment) {
            console.warn('ë°œìŒ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤:', nBestResult);
            return;
          }

          const pronunciationAssessment = nBestResult.PronunciationAssessment;
          console.log('ë°œìŒ í‰ê°€ ê²°ê³¼:', pronunciationAssessment);

          // ë‹¨ì–´ë³„ ì ìˆ˜ ì„¤ì •
          let words = pronunciationAssessment.Words || [];
          
          // NBestì—ì„œ ë‹¨ì–´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
          if (words.length === 0 && nBestResult.Words) {
            words = nBestResult.Words.map((word: any) => ({
              Word: word.Word,
              AccuracyScore: word.PronunciationAssessment?.AccuracyScore || pronunciationAssessment.AccuracyScore || 0,
              ErrorType: word.PronunciationAssessment?.ErrorType
            }));
          }

          console.log('ë‹¨ì–´ë³„ í‰ê°€:', words);
          
          if (words.length === 0) {
            // í…ìŠ¤íŠ¸ë¥¼ ë‹¨ì–´ë¡œ ë¶„í• í•˜ê³  ì „ì²´ ì ìˆ˜ë¥¼ ê° ë‹¨ì–´ì— ì ìš©
            const textWords = result.text.split(/\s+/).filter(word => word.length > 0);
            words = textWords.map(word => ({
              Word: word,
              AccuracyScore: pronunciationAssessment.AccuracyScore || 0
            }));
            console.log('í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹¨ì–´ ë¶„í• :', words);
          }

          const mappedWordScores = words.map((word: any) => {
            const score = word.AccuracyScore || pronunciationAssessment.AccuracyScore || 0;
            console.log(`ë‹¨ì–´ "${word.Word}" ì ìˆ˜:`, score);
            return {
              text: word.Word || '',
              score: score
            };
          });

          console.log('ë§¤í•‘ëœ ë‹¨ì–´ ì ìˆ˜:', mappedWordScores);
          if (mappedWordScores.length > 0) {
            setWordScores(mappedWordScores);
          }

          // í‰ê°€ ê²°ê³¼ ì„¤ì •
          const assessmentData = {
            accuracyScore: pronunciationAssessment.AccuracyScore || 0,
            fluencyScore: pronunciationAssessment.FluencyScore || 0,
            completenessScore: pronunciationAssessment.CompletenessScore || 0,
            pronScore: pronunciationAssessment.PronScore || 0,
            words: words.map((word: any) => ({
              word: word.Word || '',
              accuracyScore: word.AccuracyScore || pronunciationAssessment.AccuracyScore || 0,
              errorType: word.ErrorType
            }))
          };

          console.log('ì„¤ì •í•  í‰ê°€ ê²°ê³¼:', assessmentData);
          setAssessmentResult(assessmentData);

          // ê°ì • ë¶„ì„
          const emotionAnalysis = analyzeConfidence({
            duration: result.duration / 10000000,
            volume: nBestResult.Confidence || 0.5,
            pitch: {
              variance: Math.random() * 100
            },
            pausePattern: words.map((w: any) => ({
              duration: w.Duration || 0
            })),
            text: result.text
          });
          setEmotionResult(emotionAnalysis);

        } catch (error) {
          console.error('ë°œìŒ í‰ê°€ ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
          // ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ì„¤ì •
          setAssessmentResult(null);
          setWordScores([]);
          setEmotionResult(null);
        }
      };

      // ì—ëŸ¬ ì²˜ë¦¬
      recognizer.current.canceled = (s: unknown, e: speechsdk.SpeechRecognitionCanceledEventArgs) => {
        console.log('ì¸ì‹ ì·¨ì†Œë¨:', e.reason);
        if (e.reason === speechsdk.CancellationReason.Error) {
          console.error('ì—ëŸ¬ ìƒì„¸:', e.errorDetails);
        }
        setIsRecording(false);
      };

      setIsRecording(true);
      await recognizer.current.startContinuousRecognitionAsync();
      console.log('ë…¹ìŒ ì‹œì‘ë¨');

    } catch (error) {
      console.error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
      alert('ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      setIsRecording(false);
    }
  };

  const stopRecording = async () => {
    if (!recognizer.current) return;

    try {
      await recognizer.current.stopContinuousRecognitionAsync();
      setIsRecording(false);
      console.log('ë…¹ìŒ ì¤‘ì§€ë¨');
    } catch (error) {
      console.error('ë…¹ìŒ ì¤‘ì§€ ì‹¤íŒ¨:', error);
    }
  };

  const playAudio = () => {
    if (!player.current) return;
    
    setIsPlaying(true);
    player.current.play();
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-blue-50 to-indigo-50 py-8">
      <div className="max-w-4xl mx-auto px-4">
        {/* ìƒë‹¨ ë„¤ë¹„ê²Œì´ì…˜ */}
        <div className="flex justify-between items-center mb-8">
          <button
            onClick={() => navigate('/')}
            className="flex items-center gap-2 px-4 py-2 text-gray-600 hover:text-blue-600 hover:bg-white rounded-lg transition-all"
          >
            <span>ğŸ </span> í™ˆìœ¼ë¡œ
          </button>
          
          {/* ì–¸ì–´ ì„ íƒ */}
          <select
            value={language}
            onChange={(e) => setLanguage(e.target.value as 'ko-KR' | 'zh-CN')}
            className="px-4 py-2 rounded-lg border border-gray-300 focus:ring-2 focus:ring-blue-500 focus:border-transparent"
          >
            <option value="ko-KR">í•œêµ­ì–´</option>
            <option value="zh-CN">ì¤‘êµ­ì–´</option>
          </select>
        </div>

        {/* ë©”ì¸ ì»¨í…ì¸  */}
        <div className="bg-white rounded-xl shadow-lg p-8">
          <h1 className="text-2xl font-bold text-gray-800 mb-6">
            ğŸ¯ ì‰ë„ì‰ ì—°ìŠµ
          </h1>

          {/* í…ìŠ¤íŠ¸ ì˜ì—­ */}
          <div className="mb-8">
            <div className="flex justify-between items-center mb-4">
              <h2 className="text-lg font-semibold text-gray-700">ì—°ìŠµ í…ìŠ¤íŠ¸</h2>
              <button
                onClick={() => setShowText(!showText)}
                className="px-4 py-2 text-sm text-blue-600 hover:bg-blue-50 rounded-lg transition-all"
              >
                {showText ? 'í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê¸°' : 'í…ìŠ¤íŠ¸ ë³´ê¸°'}
              </button>
            </div>
            
            {showText && (
              <div className="bg-gray-50 rounded-lg p-4">
                <p className="text-lg text-gray-800">{sampleTexts[language]}</p>
              </div>
            )}
          </div>

          {/* ì»¨íŠ¸ë¡¤ ë²„íŠ¼ */}
          <div className="flex justify-center gap-4 mb-8">
            <button
              onClick={playAudio}
              disabled={isPlaying}
              className={`px-6 py-3 rounded-lg font-medium ${
                isPlaying
                  ? 'bg-gray-200 text-gray-500'
                  : 'bg-blue-500 text-white hover:bg-blue-600'
              }`}
            >
              {isPlaying ? 'ì¬ìƒ ì¤‘...' : 'ğŸ”Š ì›ë¬¸ ë“£ê¸°'}
            </button>
            <button
              onClick={isRecording ? stopRecording : startRecording}
              className={`px-6 py-3 rounded-lg font-medium ${
                isRecording
                  ? 'bg-red-500 text-white hover:bg-red-600'
                  : 'bg-green-500 text-white hover:bg-green-600'
              }`}
            >
              {isRecording ? 'â¹ï¸ ë…¹ìŒ ì¤‘ì§€' : 'ğŸ™ï¸ ë”°ë¼ ë§í•˜ê¸°'}
            </button>
          </div>

          {/* ë…¹ìŒëœ í…ìŠ¤íŠ¸ */}
          {recordedText && (
            <div className="mb-8">
              <h3 className="text-lg font-semibold text-gray-700 mb-3">ì¸ì‹ëœ í…ìŠ¤íŠ¸</h3>
              <div className="bg-gray-50 rounded-lg p-4">
                <p className="text-gray-800">{recordedText}</p>
              </div>
            </div>
          )}

          {/* ê°ì • ë¶„ì„ ê²°ê³¼ */}
          {emotionResult && (
            <div className="bg-white rounded-xl shadow-lg p-6 mb-6">
              <h3 className="text-lg font-semibold text-gray-800 mb-4">ê°ì • ë¶„ì„</h3>
              
              <div className="flex items-center justify-between mb-4">
                <span className="text-lg font-medium">
                  {emotionResult.emotion === 'ìì‹ ìˆìŒ' ? 'ğŸ˜Š ìì‹ ê° ìˆê²Œ ì˜ í–ˆì–´ìš”!' : 'ğŸ˜° ì¡°ê¸ˆ ê¸´ì¥í•œ ê²ƒ ê°™ì•„ìš”'}
                </span>
                <span className="text-2xl font-bold text-blue-600">
                  {Math.round(emotionResult.confidence)}ì 
                </span>
              </div>

              <div className="space-y-2">
                <div className="flex justify-between text-sm">
                  <span>ë§í•˜ê¸° ì†ë„</span>
                  <span>{Math.round(emotionResult.details.speed)} ë‹¨ì–´/ë¶„</span>
                </div>
                <div className="flex justify-between text-sm">
                  <span>ìŒëŸ‰</span>
                  <span>{Math.round(emotionResult.details.volume * 100)}%</span>
                </div>
                <div className="flex justify-between text-sm">
                  <span>ëª©ì†Œë¦¬ ë–¨ë¦¼</span>
                  <span>{Math.round(emotionResult.details.pitchVariance)}</span>
                </div>
                <div className="flex justify-between text-sm">
                  <span>ë§ì„¤ì„ íšŸìˆ˜</span>
                  <span>{emotionResult.details.pauseCount}íšŒ</span>
                </div>
              </div>
            </div>
          )}

          {/* ë°œìŒ í‰ê°€ ì‹œê°í™” */}
          {wordScores.length > 0 && (
            <div className="bg-white rounded-xl shadow-lg p-6 mb-6">
              <h3 className="text-lg font-semibold text-gray-800 mb-4">ë°œìŒ ì‹œê°í™”</h3>
              
              <div className="mb-6">
                <h4 className="text-sm font-medium text-gray-600 mb-2">ë‹¨ì–´ë³„ ì •í™•ë„</h4>
                <HeatMapVisualization wordScores={wordScores} />
              </div>

              <div>
                <h4 className="text-sm font-medium text-gray-600 mb-2">ìœ ì°½ì„± íë¦„</h4>
                <WaveAnimation fluencyScore={assessmentResult?.fluencyScore || 0} />
              </div>
            </div>
          )}

          {/* í‰ê°€ ê²°ê³¼ */}
          {assessmentResult && (
            <div className="bg-blue-50 rounded-lg p-6">
              <h3 className="text-lg font-semibold text-gray-800 mb-6">ë°œìŒ í‰ê°€ ê²°ê³¼</h3>
              
              {/* ì ìˆ˜ ê·¸ë¦¬ë“œ */}
              <div className="grid grid-cols-2 md:grid-cols-4 gap-4 mb-6">
                <div className="text-center">
                  <div className="text-2xl font-bold text-blue-600">
                    {Math.round(assessmentResult.accuracyScore) || 0}
                  </div>
                  <div className="text-sm text-gray-600">ì •í™•ë„</div>
                </div>
                <div className="text-center">
                  <div className="text-2xl font-bold text-green-600">
                    {Math.round(assessmentResult.fluencyScore) || 0}
                  </div>
                  <div className="text-sm text-gray-600">ìœ ì°½ì„±</div>
                </div>
                <div className="text-center">
                  <div className="text-2xl font-bold text-purple-600">
                    {Math.round(assessmentResult.completenessScore) || 0}
                  </div>
                  <div className="text-sm text-gray-600">ì™„ì„±ë„</div>
                </div>
                <div className="text-center">
                  <div className="text-2xl font-bold text-orange-600">
                    {Math.round(assessmentResult.pronScore) || 0}
                  </div>
                  <div className="text-sm text-gray-600">ì¢…í•© ì ìˆ˜</div>
                </div>
              </div>

              {/* ë‹¨ì–´ë³„ ë¶„ì„ */}
              {assessmentResult.words && assessmentResult.words.length > 0 && (
                <div>
                  <h4 className="font-semibold text-gray-700 mb-3">ë‹¨ì–´ë³„ ë¶„ì„</h4>
                  <div className="grid gap-2">
                    {assessmentResult.words.map((word, index) => (
                      <div
                        key={index}
                        className="flex items-center justify-between bg-white rounded-lg p-3"
                      >
                        <span className="font-medium">{word.word}</span>
                        <div className="flex items-center gap-3">
                          <span className={`text-sm ${
                            (word.accuracyScore || 0) >= 80 ? 'text-green-600' :
                            (word.accuracyScore || 0) >= 60 ? 'text-yellow-600' :
                            'text-red-600'
                          }`}>
                            {Math.round(word.accuracyScore || 0)}ì 
                          </span>
                          {word.errorType && (
                            <span className="text-xs text-red-500">
                              {word.errorType}
                            </span>
                          )}
                        </div>
                      </div>
                    ))}
                  </div>
                </div>
              )}
            </div>
          )}
        </div>
      </div>

      {/* ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ (ìˆ¨ê¹€) */}
      <audio
        ref={player}
        onEnded={() => setIsPlaying(false)}
        style={{ display: 'none' }}
      >
        <source src="/path/to/audio.mp3" type="audio/mpeg" />
      </audio>
    </div>
  );
};

export default ShadowingPractice; 